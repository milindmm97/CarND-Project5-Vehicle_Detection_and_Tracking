{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using trained model for Vechile detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milind\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import model\n",
    "from scipy.ndimage.measurements import label\n",
    "import cv2\n",
    "import os.path\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read input frame without car "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_no_car = cv2.imread('frame0.jpg',3)\n",
    "cv2.imshow('image',frame_no_car)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_car1 = cv2.imread('frame1000.jpg',3)\n",
    "cv2.imshow('image',frame_car1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The region of interest for vehicle detection starts at an approximately 400th pixel from the top and spans vertically for about 260 pixels. That said, we have a region of interest with the dimensions of 260x1280x3, where 3 is the number of color channels, starting at 400th pixel vertically.\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inW 1280   inCh 3   inH 260\n"
     ]
    }
   ],
   "source": [
    "crop=(400, 660)\n",
    "imgInputShape=(720, 1280, 3)\n",
    "bottomClip = imgInputShape[0] - crop[1]\n",
    "inH = imgInputShape[0] - crop[0] - bottomClip\n",
    "inW = imgInputShape[1]\n",
    "inCh = imgInputShape[2]\n",
    "print('inW',inW, ' ', 'inCh',inCh,' ','inH',inH)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnModel,cnnModelName=model.poolerPico(inputShape=(inH, inW, inCh))\n",
    "cnnModel.load_weights('{}.h5'.format(cnnModelName))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top convolutional layer now has the dimensionality of (? ,25, 153, 1), where 25x53 actually represents a miniature map of predictions that will ultimately be projected to the original hi-res image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_3 (Lambda)            (None, 260, 1280, 3)      0         \n",
      "_________________________________________________________________\n",
      "cv0 (Conv2D)                 (None, 260, 1280, 16)     448       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 260, 1280, 16)     0         \n",
      "_________________________________________________________________\n",
      "cv1 (Conv2D)                 (None, 260, 1280, 32)     4640      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 260, 1280, 32)     0         \n",
      "_________________________________________________________________\n",
      "cv2 (Conv2D)                 (None, 260, 1280, 64)     18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 160, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 160, 64)       0         \n",
      "_________________________________________________________________\n",
      "fcn (Conv2D)                 (None, 25, 153, 1)        4097      \n",
      "=================================================================\n",
      "Total params: 27,681\n",
      "Trainable params: 27,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ppico'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnModel.summary()\n",
    "cnnModelName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the ROI from input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi= frame_car1[crop[0]:crop[1],:]\n",
    "roi\n",
    "cv2.imshow('Cropped',roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI is obtained \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 260)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roiW, roiH = roi.shape[1], roi.shape[0]\n",
    "roiW , roiH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[5.9501699e-04],\n",
       "         [6.6978246e-04],\n",
       "         [2.0230282e-03],\n",
       "         ...,\n",
       "         [5.1967281e-01],\n",
       "         [9.0813065e-01],\n",
       "         [8.9557505e-01]],\n",
       "\n",
       "        [[2.3579902e-04],\n",
       "         [1.5181024e-04],\n",
       "         [1.9854130e-04],\n",
       "         ...,\n",
       "         [9.5699340e-01],\n",
       "         [9.9788672e-01],\n",
       "         [9.9815530e-01]],\n",
       "\n",
       "        [[9.3317780e-05],\n",
       "         [9.0293048e-05],\n",
       "         [7.9577942e-05],\n",
       "         ...,\n",
       "         [9.1399634e-01],\n",
       "         [9.9113768e-01],\n",
       "         [9.9854350e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.1876919e-02],\n",
       "         [8.1976475e-03],\n",
       "         [5.6965919e-03],\n",
       "         ...,\n",
       "         [2.4859210e-02],\n",
       "         [2.3544349e-02],\n",
       "         [2.3016497e-02]],\n",
       "\n",
       "        [[1.1448142e-02],\n",
       "         [9.3642250e-03],\n",
       "         [9.2958137e-03],\n",
       "         ...,\n",
       "         [2.5712144e-02],\n",
       "         [2.7567841e-02],\n",
       "         [2.8327381e-02]],\n",
       "\n",
       "        [[1.3626013e-02],\n",
       "         [1.8201223e-02],\n",
       "         [2.3568133e-02],\n",
       "         ...,\n",
       "         [3.0811863e-02],\n",
       "         [2.9734839e-02],\n",
       "         [3.2206688e-02]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Going 4-D\n",
    "roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "# Single-Feature top convolutional layer, which represents a\n",
    "# miniaturized (25x153) version of the ROI with the vehicle's probability at each point\n",
    "detectionMap = cnnModel.predict(roi)\n",
    "detectionMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 25, 153, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectionMap.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection Map is obtained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 153)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectionMap.shape[1], detectionMap.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.4, 8.366013071895425)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionMapH, predictionMapW = detectionMap.shape[1], detectionMap.shape[2]\n",
    "\n",
    "ratioH, ratioW = roiH / predictionMapH, roiW / predictionMapW\n",
    "ratioH, ratioW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 153)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Prediction output is 4-D tensor: (1, H, W, 1) in this particular case,\n",
    "#thus converting to 2-D, effectively represents it as a single-channel image\n",
    "detectionMap = detectionMap.reshape(detectionMap.shape[1], detectionMap.shape[2])\n",
    "detectionMap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidenceThrd=.7\n",
    "diagKernel = [[1, 1, 1],\n",
    "              [1, 1, 1],\n",
    "              [1, 1, 1]]\n",
    "#defines feature connections. Here 8 connectivity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 2, 2],\n",
       "        [0, 0, 0, ..., 2, 2, 2],\n",
       "        [0, 0, 0, ..., 2, 2, 2],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]), 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectionMap = detectionMap > confidenceThrd\n",
    "labels = label(detectionMap, structure= diagKernel)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label indicated features labelled in total "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To draw the boxes for the frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((799, 400), (863, 464)),\n",
       " ((807, 400), (871, 464)),\n",
       " ((814, 400), (878, 464)),\n",
       " ((822, 400), (886, 464)),\n",
       " ((829, 400), (893, 464)),\n",
       " ((837, 400), (901, 464)),\n",
       " ((844, 400), (908, 464)),\n",
       " ((852, 400), (916, 464)),\n",
       " ((859, 400), (923, 464)),\n",
       " ((867, 400), (931, 464)),\n",
       " ((792, 409), (856, 473)),\n",
       " ((799, 409), (863, 473)),\n",
       " ((807, 409), (871, 473)),\n",
       " ((814, 409), (878, 473)),\n",
       " ((822, 409), (886, 473)),\n",
       " ((829, 409), (893, 473)),\n",
       " ((837, 409), (901, 473)),\n",
       " ((844, 409), (908, 473)),\n",
       " ((852, 409), (916, 473)),\n",
       " ((859, 409), (923, 473)),\n",
       " ((867, 409), (931, 473)),\n",
       " ((784, 419), (848, 483)),\n",
       " ((792, 419), (856, 483)),\n",
       " ((799, 419), (863, 483)),\n",
       " ((807, 419), (871, 483)),\n",
       " ((814, 419), (878, 483)),\n",
       " ((822, 419), (886, 483)),\n",
       " ((829, 419), (893, 483)),\n",
       " ((837, 419), (901, 483)),\n",
       " ((844, 419), (908, 483)),\n",
       " ((852, 419), (916, 483)),\n",
       " ((859, 419), (923, 483)),\n",
       " ((867, 419), (931, 483)),\n",
       " ((784, 428), (848, 492)),\n",
       " ((792, 428), (856, 492)),\n",
       " ((799, 428), (863, 492)),\n",
       " ((807, 428), (871, 492)),\n",
       " ((814, 428), (878, 492)),\n",
       " ((822, 428), (886, 492)),\n",
       " ((829, 428), (893, 492)),\n",
       " ((837, 428), (901, 492)),\n",
       " ((844, 428), (908, 492)),\n",
       " ((852, 428), (916, 492)),\n",
       " ((859, 428), (923, 492)),\n",
       " ((867, 428), (931, 492)),\n",
       " ((784, 438), (848, 502)),\n",
       " ((792, 438), (856, 502)),\n",
       " ((799, 438), (863, 502)),\n",
       " ((807, 438), (871, 502)),\n",
       " ((814, 438), (878, 502)),\n",
       " ((822, 438), (886, 502)),\n",
       " ((829, 438), (893, 502)),\n",
       " ((837, 438), (901, 502)),\n",
       " ((844, 438), (908, 502)),\n",
       " ((852, 438), (916, 502)),\n",
       " ((859, 438), (923, 502)),\n",
       " ((792, 447), (856, 511)),\n",
       " ((799, 447), (863, 511)),\n",
       " ((807, 447), (871, 511)),\n",
       " ((814, 447), (878, 511)),\n",
       " ((822, 447), (886, 511)),\n",
       " ((829, 447), (893, 511)),\n",
       " ((837, 447), (901, 511)),\n",
       " ((844, 447), (908, 511)),\n",
       " ((792, 457), (856, 521)),\n",
       " ((799, 457), (863, 521)),\n",
       " ((807, 457), (871, 521)),\n",
       " ((814, 457), (878, 521)),\n",
       " ((822, 457), (886, 521)),\n",
       " ((829, 457), (893, 521)),\n",
       " ((837, 457), (901, 521)),\n",
       " ((844, 457), (908, 521)),\n",
       " ((807, 466), (871, 530)),\n",
       " ((814, 466), (878, 530)),\n",
       " ((1077, 400), (1141, 464)),\n",
       " ((1085, 400), (1149, 464)),\n",
       " ((1131, 400), (1195, 464)),\n",
       " ((1139, 400), (1203, 464)),\n",
       " ((1146, 400), (1210, 464)),\n",
       " ((1154, 400), (1218, 464)),\n",
       " ((1161, 400), (1225, 464)),\n",
       " ((1169, 400), (1233, 464)),\n",
       " ((1177, 400), (1241, 464)),\n",
       " ((1184, 400), (1248, 464)),\n",
       " ((1192, 400), (1256, 464)),\n",
       " ((1200, 400), (1264, 464)),\n",
       " ((1207, 400), (1271, 464)),\n",
       " ((1223, 400), (1287, 464)),\n",
       " ((1230, 400), (1294, 464)),\n",
       " ((1077, 409), (1141, 473)),\n",
       " ((1085, 409), (1149, 473)),\n",
       " ((1093, 409), (1157, 473)),\n",
       " ((1100, 409), (1164, 473)),\n",
       " ((1108, 409), (1172, 473)),\n",
       " ((1116, 409), (1180, 473)),\n",
       " ((1123, 409), (1187, 473)),\n",
       " ((1131, 409), (1195, 473)),\n",
       " ((1139, 409), (1203, 473)),\n",
       " ((1146, 409), (1210, 473)),\n",
       " ((1154, 409), (1218, 473)),\n",
       " ((1161, 409), (1225, 473)),\n",
       " ((1169, 409), (1233, 473)),\n",
       " ((1177, 409), (1241, 473)),\n",
       " ((1184, 409), (1248, 473)),\n",
       " ((1192, 409), (1256, 473)),\n",
       " ((1200, 409), (1264, 473)),\n",
       " ((1207, 409), (1271, 473)),\n",
       " ((1215, 409), (1279, 473)),\n",
       " ((1223, 409), (1287, 473)),\n",
       " ((1230, 409), (1294, 473)),\n",
       " ((1039, 419), (1103, 483)),\n",
       " ((1047, 419), (1111, 483)),\n",
       " ((1054, 419), (1118, 483)),\n",
       " ((1062, 419), (1126, 483)),\n",
       " ((1070, 419), (1134, 483)),\n",
       " ((1077, 419), (1141, 483)),\n",
       " ((1085, 419), (1149, 483)),\n",
       " ((1093, 419), (1157, 483)),\n",
       " ((1100, 419), (1164, 483)),\n",
       " ((1108, 419), (1172, 483)),\n",
       " ((1116, 419), (1180, 483)),\n",
       " ((1123, 419), (1187, 483)),\n",
       " ((1131, 419), (1195, 483)),\n",
       " ((1139, 419), (1203, 483)),\n",
       " ((1146, 419), (1210, 483)),\n",
       " ((1154, 419), (1218, 483)),\n",
       " ((1161, 419), (1225, 483)),\n",
       " ((1169, 419), (1233, 483)),\n",
       " ((1177, 419), (1241, 483)),\n",
       " ((1184, 419), (1248, 483)),\n",
       " ((1192, 419), (1256, 483)),\n",
       " ((1200, 419), (1264, 483)),\n",
       " ((1207, 419), (1271, 483)),\n",
       " ((1215, 419), (1279, 483)),\n",
       " ((1223, 419), (1287, 483)),\n",
       " ((1230, 419), (1294, 483)),\n",
       " ((1031, 428), (1095, 492)),\n",
       " ((1039, 428), (1103, 492)),\n",
       " ((1047, 428), (1111, 492)),\n",
       " ((1054, 428), (1118, 492)),\n",
       " ((1062, 428), (1126, 492)),\n",
       " ((1070, 428), (1134, 492)),\n",
       " ((1085, 428), (1149, 492)),\n",
       " ((1093, 428), (1157, 492)),\n",
       " ((1100, 428), (1164, 492)),\n",
       " ((1108, 428), (1172, 492)),\n",
       " ((1116, 428), (1180, 492)),\n",
       " ((1123, 428), (1187, 492)),\n",
       " ((1131, 428), (1195, 492)),\n",
       " ((1139, 428), (1203, 492)),\n",
       " ((1146, 428), (1210, 492)),\n",
       " ((1154, 428), (1218, 492)),\n",
       " ((1161, 428), (1225, 492)),\n",
       " ((1169, 428), (1233, 492)),\n",
       " ((1177, 428), (1241, 492)),\n",
       " ((1184, 428), (1248, 492)),\n",
       " ((1192, 428), (1256, 492)),\n",
       " ((1200, 428), (1264, 492)),\n",
       " ((1207, 428), (1271, 492)),\n",
       " ((1215, 428), (1279, 492)),\n",
       " ((1223, 428), (1287, 492)),\n",
       " ((1230, 428), (1294, 492)),\n",
       " ((1047, 438), (1111, 502)),\n",
       " ((1054, 438), (1118, 502)),\n",
       " ((1062, 438), (1126, 502)),\n",
       " ((1085, 438), (1149, 502)),\n",
       " ((1093, 438), (1157, 502)),\n",
       " ((1100, 438), (1164, 502)),\n",
       " ((1108, 438), (1172, 502)),\n",
       " ((1116, 438), (1180, 502)),\n",
       " ((1123, 438), (1187, 502)),\n",
       " ((1131, 438), (1195, 502)),\n",
       " ((1139, 438), (1203, 502)),\n",
       " ((1146, 438), (1210, 502)),\n",
       " ((1154, 438), (1218, 502)),\n",
       " ((1161, 438), (1225, 502)),\n",
       " ((1169, 438), (1233, 502)),\n",
       " ((1177, 438), (1241, 502)),\n",
       " ((1184, 438), (1248, 502)),\n",
       " ((1192, 438), (1256, 502)),\n",
       " ((1200, 438), (1264, 502)),\n",
       " ((1207, 438), (1271, 502)),\n",
       " ((1215, 438), (1279, 502)),\n",
       " ((1223, 438), (1287, 502)),\n",
       " ((1230, 438), (1294, 502)),\n",
       " ((1047, 447), (1111, 511)),\n",
       " ((1062, 447), (1126, 511)),\n",
       " ((1070, 447), (1134, 511)),\n",
       " ((1077, 447), (1141, 511)),\n",
       " ((1085, 447), (1149, 511)),\n",
       " ((1093, 447), (1157, 511)),\n",
       " ((1100, 447), (1164, 511)),\n",
       " ((1108, 447), (1172, 511)),\n",
       " ((1116, 447), (1180, 511)),\n",
       " ((1123, 447), (1187, 511)),\n",
       " ((1131, 447), (1195, 511)),\n",
       " ((1139, 447), (1203, 511)),\n",
       " ((1146, 447), (1210, 511)),\n",
       " ((1154, 447), (1218, 511)),\n",
       " ((1161, 447), (1225, 511)),\n",
       " ((1169, 447), (1233, 511)),\n",
       " ((1177, 447), (1241, 511)),\n",
       " ((1184, 447), (1248, 511)),\n",
       " ((1192, 447), (1256, 511)),\n",
       " ((1200, 447), (1264, 511)),\n",
       " ((1207, 447), (1271, 511)),\n",
       " ((1215, 447), (1279, 511)),\n",
       " ((1223, 447), (1287, 511)),\n",
       " ((1230, 447), (1294, 511)),\n",
       " ((1062, 457), (1126, 521)),\n",
       " ((1070, 457), (1134, 521)),\n",
       " ((1085, 457), (1149, 521)),\n",
       " ((1100, 457), (1164, 521)),\n",
       " ((1108, 457), (1172, 521)),\n",
       " ((1116, 457), (1180, 521)),\n",
       " ((1123, 457), (1187, 521)),\n",
       " ((1131, 457), (1195, 521)),\n",
       " ((1139, 457), (1203, 521)),\n",
       " ((1146, 457), (1210, 521)),\n",
       " ((1154, 457), (1218, 521)),\n",
       " ((1161, 457), (1225, 521)),\n",
       " ((1169, 457), (1233, 521)),\n",
       " ((1177, 457), (1241, 521)),\n",
       " ((1184, 457), (1248, 521)),\n",
       " ((1207, 457), (1271, 521)),\n",
       " ((1123, 466), (1187, 530)),\n",
       " ((1131, 466), (1195, 530)),\n",
       " ((1139, 466), (1203, 530)),\n",
       " ((1146, 466), (1210, 530)),\n",
       " ((1154, 466), (1218, 530)),\n",
       " ((95, 442), (159, 506)),\n",
       " ((102, 442), (166, 506)),\n",
       " ((110, 442), (174, 506)),\n",
       " ((117, 442), (181, 506))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotPoints = []\n",
    "detectionPointSize = 64\n",
    "\n",
    "        # Considering obtained labels as vehicles.\n",
    "for vehicleID in range(labels[1]):\n",
    "    nz = (labels[0] == vehicleID + 1).nonzero()\n",
    "    nzY = np.array(nz[0])\n",
    "    nzX = np.array(nz[1])\n",
    "\n",
    "    # +/-'s are manually derived adjustments for more appropriate boxes visualization\n",
    "    xMin = np.min(nzX) - 32\n",
    "    xMax = np.max(nzX) + 32\n",
    "\n",
    "    yMin = np.min(nzY)\n",
    "    yMax = np.max(nzY) + 64\n",
    "\n",
    "    # Used to keep generated bounding boxes within a range of the label (a.k.a. vehicle) boundaries\n",
    "    spanX = xMax - xMin\n",
    "    spanY = yMax - yMin\n",
    "\n",
    "    for x, y in zip(nzX, nzY):\n",
    "\n",
    "        # Adjustment offsets for a box starting point.\n",
    "        # Ranges from 0 for the left(upper)-most to detectionPointSize for right(bottom)-most\n",
    "        offsetX = (x - xMin) / spanX * detectionPointSize\n",
    "        offsetY = (y - yMin) / spanY * detectionPointSize\n",
    "\n",
    "        # Getting boundaries in ROI coordinates scale (multiplying by ratioW, ratioH)\n",
    "        topLeftX = int(round(x * ratioW - offsetX, 0))\n",
    "        topLeftY = int(round(y * ratioH - offsetY, 0))\n",
    "        bottomLeftX = topLeftX + detectionPointSize\n",
    "        bottomLeftY = topLeftY + detectionPointSize\n",
    "\n",
    "        topLeft = (topLeftX, crop[0] + topLeftY)\n",
    "        bottomRight = (bottomLeftX, crop[0] + bottomLeftY)\n",
    "\n",
    "        hotPoints.append((topLeft, bottomRight))\n",
    "        \n",
    "hotPoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Heat Maps from the hot points obtained from the detection Maps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the Heat Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "src= frame_car1\n",
    "sampleMask = np.zeros_like(src[:, :, 0]).astype(np.float)\n",
    "bBoxes=hotPoints\n",
    "mask=sampleMask\n",
    "for box in bBoxes:\n",
    "        # box as ((x, y), (x, y))\n",
    "        topY = box[0][1]\n",
    "        bottomY = box[1][1]\n",
    "        leftX = box[0][0]\n",
    "        rightX = box[1][0]\n",
    "\n",
    "        mask[topY:bottomY, leftX:rightX] += 1\n",
    "\n",
    "        mask = np.clip(mask, 0, 255)\n",
    "        \n",
    "heatMap = mask \n",
    "        \n",
    "cv2.imshow('heat',heatMap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap=cv2.COLORMAP_JET\n",
    "heatMapInt = cv2.equalizeHist(heatMap.astype(np.uint8))\n",
    "heatColor = cv2.applyColorMap(heatMapInt, cmap)\n",
    "heatColor = cv2.cvtColor(heatColor, code=cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('heat',heatColor)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
